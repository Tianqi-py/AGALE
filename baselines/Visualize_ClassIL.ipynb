{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Visualize ClassIL on Yelp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "import torch\n",
    "import scipy.io\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import Yelp\n",
    "from utils import sparse_mx_to_torch_sparse_tensor\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset Yelp...\n",
      "dataset loaded\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print('Loading dataset Yelp...')\n",
    "dataset = Yelp(root='../../tmp/Yelp')\n",
    "data = dataset[0]\n",
    "labels = data.y\n",
    "features = data.x\n",
    "edge_index = data.edge_index\n",
    "print(\"dataset loaded\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes in this class 58722\n",
      "number of nodes in this class 71095\n",
      "number of nodes in this class 84641\n",
      "number of nodes in this class 223504\n",
      "number of nodes in this class 235923\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 191243\n",
      "###################\n",
      "number of nodes in this class 50405\n",
      "number of nodes in this class 141439\n",
      "number of nodes in this class 154457\n",
      "number of nodes in this class 193520\n",
      "number of nodes in this class 253743\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 190810\n",
      "###################\n",
      "number of nodes in this class 192696\n",
      "number of nodes in this class 241575\n",
      "number of nodes in this class 271709\n",
      "number of nodes in this class 399202\n",
      "number of nodes in this class 439038\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 296751\n",
      "###################\n",
      "number of nodes in this class 16177\n",
      "number of nodes in this class 43398\n",
      "number of nodes in this class 54279\n",
      "number of nodes in this class 72095\n",
      "number of nodes in this class 82956\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 70153\n",
      "###################\n",
      "number of nodes in this class 14510\n",
      "number of nodes in this class 81141\n",
      "number of nodes in this class 158756\n",
      "number of nodes in this class 197233\n",
      "number of nodes in this class 241473\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 173691\n",
      "###################\n",
      "number of nodes in this class 187410\n",
      "number of nodes in this class 205760\n",
      "number of nodes in this class 221595\n",
      "number of nodes in this class 348824\n",
      "number of nodes in this class 381064\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 268051\n",
      "###################\n",
      "number of nodes in this class 54479\n",
      "number of nodes in this class 120033\n",
      "number of nodes in this class 291706\n",
      "number of nodes in this class 383423\n",
      "number of nodes in this class 468510\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 312211\n",
      "###################\n",
      "number of nodes in this class 54842\n",
      "number of nodes in this class 117064\n",
      "number of nodes in this class 151739\n",
      "number of nodes in this class 194027\n",
      "number of nodes in this class 206575\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 155037\n",
      "###################\n",
      "number of nodes in this class 18154\n",
      "number of nodes in this class 134691\n",
      "number of nodes in this class 216439\n",
      "number of nodes in this class 237301\n",
      "number of nodes in this class 330566\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 234709\n",
      "###################\n",
      "number of nodes in this class 14858\n",
      "number of nodes in this class 37702\n",
      "number of nodes in this class 141215\n",
      "number of nodes in this class 165232\n",
      "number of nodes in this class 190585\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 154564\n",
      "###################\n",
      "number of nodes in this class 80488\n",
      "number of nodes in this class 207817\n",
      "number of nodes in this class 352509\n",
      "number of nodes in this class 410371\n",
      "number of nodes in this class 442245\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 272426\n",
      "###################\n",
      "number of nodes in this class 99562\n",
      "number of nodes in this class 186761\n",
      "number of nodes in this class 246440\n",
      "number of nodes in this class 260370\n",
      "number of nodes in this class 275445\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 199989\n",
      "###################\n",
      "number of nodes in this class 124849\n",
      "number of nodes in this class 158562\n",
      "number of nodes in this class 428675\n",
      "number of nodes in this class 484240\n",
      "number of nodes in this class 507151\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 346114\n",
      "###################\n",
      "number of nodes in this class 28558\n",
      "number of nodes in this class 40970\n",
      "number of nodes in this class 306863\n",
      "number of nodes in this class 439941\n",
      "number of nodes in this class 449799\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 339963\n",
      "###################\n",
      "number of nodes in this class 116696\n",
      "number of nodes in this class 129285\n",
      "number of nodes in this class 187147\n",
      "number of nodes in this class 272063\n",
      "number of nodes in this class 358647\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 218760\n",
      "###################\n",
      "number of nodes in this class 85275\n",
      "number of nodes in this class 141069\n",
      "number of nodes in this class 151632\n",
      "number of nodes in this class 163519\n",
      "number of nodes in this class 283725\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 212694\n",
      "###################\n",
      "number of nodes in this class 529888\n",
      "number of nodes in this class 551952\n",
      "number of nodes in this class 623276\n",
      "number of nodes in this class 819336\n",
      "number of nodes in this class 836379\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 557721\n",
      "###################\n",
      "number of nodes in this class 13739\n",
      "number of nodes in this class 82161\n",
      "number of nodes in this class 114608\n",
      "number of nodes in this class 161350\n",
      "number of nodes in this class 179194\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 139394\n",
      "###################\n",
      "number of nodes in this class 19651\n",
      "number of nodes in this class 39961\n",
      "number of nodes in this class 88921\n",
      "number of nodes in this class 121418\n",
      "number of nodes in this class 150390\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 115270\n",
      "###################\n",
      "number of nodes in this class 88021\n",
      "number of nodes in this class 103606\n",
      "number of nodes in this class 126832\n",
      "number of nodes in this class 199979\n",
      "number of nodes in this class 451726\n",
      "total number of nodes after removing duplicats of node-ids because of multi-labelness 320350\n",
      "###################\n"
     ]
    }
   ],
   "source": [
    "# groups assignment\n",
    "n_cls = labels.shape[1]\n",
    "cls_order = shuffle(range(n_cls))\n",
    "n_cls_per_t = 5\n",
    "groups_idx = [tuple(cls_order[i:i+n_cls_per_t]) for i in range(0, n_cls-1, n_cls_per_t)]\n",
    "#print(\"groups index\", groups_idx)\n",
    "\n",
    "clses = torch.transpose(labels, 0, 1)\n",
    "cls_asgn = {}\n",
    "for i, label in enumerate(clses):\n",
    "    cls_asgn[i] = torch.nonzero(label).flatten()\n",
    "\n",
    "groups = {}\n",
    "for g in groups_idx:\n",
    "    groups[g] = []\n",
    "for g in groups_idx:\n",
    "    assert g in groups.keys()\n",
    "    for c in g:\n",
    "        groups[g].extend(cls_asgn[c].tolist())\n",
    "\n",
    "        print(\"number of nodes in this class\",len(groups[g]))\n",
    "    # note only once the nodes belong to multiple classes\n",
    "    groups[g] = list(set(groups[g]))\n",
    "    groups[g].sort()\n",
    "    print(\"total number of nodes after removing duplicats of node-ids because of multi-labelness\", len(groups[g]))\n",
    "    print(\"###################\")\n",
    "\n",
    "# splits is a nested dictionary\n",
    "# key: groups, value: (key:train, val, test; value:node_ids)\n",
    "# each time step, nodes have no more than classes seen so far\n",
    "\n",
    "# split the train-val-test within each class\n",
    "splits = {}\n",
    "for g in list(groups.keys()):\n",
    "    split = {}\n",
    "    # get all the nodes in this group\n",
    "    node_ids = groups[g]\n",
    "\n",
    "    # split the nodes into train-val-test: 60-10-30\n",
    "    ids_train, ids_val_test = train_test_split(node_ids, test_size=0.4, random_state=42)\n",
    "    ids_val, ids_test = train_test_split(ids_val_test, test_size=0.75, random_state=41)\n",
    "    # write in the dictionary\n",
    "    split[\"train\"] = ids_train\n",
    "    split[\"val\"] = ids_val\n",
    "    split[\"test\"] = ids_test\n",
    "    splits[g] = split\n",
    "\n",
    "#print(splits)\n",
    "\n",
    "num_nodes = labels.shape[0]\n",
    "\n",
    "G = Data(x=features,\n",
    "         edge_index=edge_index,\n",
    "         y=labels)\n",
    "\n",
    "G.n_id = torch.arange(num_nodes)\n",
    "G.splits = splits\n",
    "G.groups = groups"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups of classes for each time step:  dict_keys([(63, 62, 98, 25, 92), (52, 90, 79, 29, 54), (82, 42, 72, 53, 27), (49, 80, 96, 88, 95), (91, 7, 48, 41, 67), (9, 61, 85, 5, 32), (99, 83, 8, 76, 31), (6, 23, 55, 94, 12), (66, 43, 36, 50, 75), (60, 74, 17, 77, 57), (11, 19, 10, 37, 71), (21, 47, 86, 44, 78), (0, 13, 2, 40, 35), (89, 70, 24, 14, 81), (3, 69, 38, 16, 45), (65, 56, 93, 97, 39), (1, 59, 15, 28, 20), (30, 18, 51, 58, 26), (87, 84, 4, 46, 68), (64, 33, 73, 34, 22)])\n",
      "##########################################################################\n",
      "size of each group:  [191243, 190810, 296751, 70153, 173691, 268051, 312211, 155037, 234709, 154564, 272426, 199989, 346114, 339963, 218760, 212694, 557721, 139394, 115270, 320350]\n",
      "##########################################################################\n",
      "total number of nodes in Yelp:  716847\n"
     ]
    }
   ],
   "source": [
    "# statistics\n",
    "print(\"Groups of classes for each time step: \", G.groups.keys())\n",
    "print(\"##########################################################################\")\n",
    "print(\"size of each group: \", [len(G.groups[g]) for g in G.groups.keys()])\n",
    "print(\"##########################################################################\")\n",
    "print(\"total number of nodes in Yelp: \", G.x.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([(63, 62, 98, 25, 92), (52, 90, 79, 29, 54), (82, 42, 72, 53, 27), (49, 80, 96, 88, 95), (91, 7, 48, 41, 67), (9, 61, 85, 5, 32), (99, 83, 8, 76, 31), (6, 23, 55, 94, 12), (66, 43, 36, 50, 75), (60, 74, 17, 77, 57), (11, 19, 10, 37, 71), (21, 47, 86, 44, 78), (0, 13, 2, 40, 35), (89, 70, 24, 14, 81), (3, 69, 38, 16, 45), (65, 56, 93, 97, 39), (1, 59, 15, 28, 20), (30, 18, 51, 58, 26), (87, 84, 4, 46, 68), (64, 33, 73, 34, 22)])\n"
     ]
    }
   ],
   "source": [
    "# splits\n",
    "print(G.splits.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicats in the class group1 and group2:  78047\n"
     ]
    }
   ],
   "source": [
    "g1 = G.splits[list(G.splits.keys())[0]]\n",
    "train_id_g1 = g1[\"train\"]\n",
    "val_id_g1 = g1[\"val\"]\n",
    "test_id_g1 = g1[\"test\"]\n",
    "\n",
    "g2 = G.splits[list(G.splits.keys())[1]]\n",
    "train_id_g2 = g2[\"train\"]\n",
    "val_id_g2 = g2[\"val\"]\n",
    "test_id_g2 = g2[\"test\"]\n",
    "g1_id = g1[\"train\"] + g1[\"val\"] + g1[\"test\"]\n",
    "g2_id = g2[\"train\"] + g2[\"val\"] + g2[\"test\"]\n",
    "\n",
    "print(\"number of duplicats in the class group1 and group2: \",\n",
    "      len(g1_id)+len(g2_id)-len(list(set(g1_id + g2_id))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number sampled of common nodes:  406\n"
     ]
    }
   ],
   "source": [
    "# sample some common nodes from group1 and group3\n",
    "sample_in_g1 = g1_id[:1000]\n",
    "target = [s for s in sample_in_g1 if s in g2_id]\n",
    "print(\"number sampled of common nodes: \", len(target))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take node 372363 as an example\n",
      "it is in the training set of group 1\n",
      "and it is in the test set of group 2\n"
     ]
    }
   ],
   "source": [
    "# take one node\n",
    "id = target[0]\n",
    "print(\"take node\", id, \"as an example\")\n",
    "if id in train_id_g1:\n",
    "    print(\"it is in the training set of group 1\")\n",
    "if id in val_id_g1:\n",
    "    print(\"it is in the val set of group 1\")\n",
    "if id in test_id_g1:\n",
    "    print(\"it is in the test set of group 1\")\n",
    "\n",
    "if id in train_id_g2:\n",
    "    print(\"and it is in the training set of group 2\")\n",
    "if id in val_id_g2:\n",
    "    print(\"and it is in the val set of group 2\")\n",
    "if id in test_id_g2:\n",
    "    print(\"and it is in the test set of group 2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from torch_geometric.utils import mask\n",
    "from torch_geometric.utils import subgraph\n",
    "def map_edge_index(node_ids, edge_index_complete):\n",
    "    # input the indices of the nodes of the subgraph in the graph,\n",
    "    # transform the edge_index into the subgraph index\n",
    "    num_edge = edge_index_complete.shape[1]\n",
    "    map_book = {x.item(): i for i, x in enumerate(node_ids)}\n",
    "    edge_index_mapped = map(lambda node: map_book[node], np.asarray(edge_index_complete.flatten()))\n",
    "    edge_index = torch.Tensor(list(edge_index_mapped))\n",
    "    edge_index = torch.reshape(edge_index, (2, num_edge)).long()\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "def map_split(node_ids, split):\n",
    "    # map the split ids into the subgraph\n",
    "    map_book = {x.item(): i for i, x in enumerate(node_ids)}\n",
    "\n",
    "    mapped_split = {}\n",
    "    for key in split.keys():\n",
    "        mapped_split[key] = list(map(lambda node: map_book[node], np.asarray(split[key])))\n",
    "\n",
    "    return mapped_split\n",
    "\n",
    "\n",
    "def prepare_sub_graph(G, key, Cross_Task_Message_Passing=False):\n",
    "    # task incremental\n",
    "    # prepare subgraph for one task\n",
    "    # target classes for each task, note for catastrophic forgetting evaluation\n",
    "    target_classes = list(key)\n",
    "    print(target_classes)\n",
    "    #print(G.groups[key])\n",
    "    # sorted nodes ids in the group\n",
    "    node_ids_g = torch.Tensor(G.groups[key]).int().long()\n",
    "\n",
    "    # also include the edges that connect the nodes in the subgraph with those that are not in the subgraph\n",
    "    node_mask = mask.index_to_mask(node_ids_g, size=G.num_nodes)\n",
    "\n",
    "    # allow nodes from other task to pass information to the nodes for this task\n",
    "    if Cross_Task_Message_Passing:\n",
    "        # or operation of two boolean lists\n",
    "        edge_mask = node_mask[G.edge_index[0]] + node_mask[G.edge_index[1]]\n",
    "        edge_index_g = G.edge_index[:, edge_mask]\n",
    "        # all nodes in the subgraph(including target nodes and their neighbors) in the original graph\n",
    "        node_ids_g_all = torch.unique(edge_index_g.flatten()).long()\n",
    "        # index of target nodes in the graph\n",
    "        target_ids_g = [i for i, n in enumerate(node_ids_g_all) if n in node_ids_g]\n",
    "\n",
    "        # !!!!!!!!!!!!!convert target id into the subgraph !!!!!!!!!!!!!!!!!!!\n",
    "        # evaluate only on the target nodes!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        #target_ids_sub =\n",
    "        # get the edge_index in the subgraph\n",
    "        edge_index_sub = map_edge_index(node_ids_g_all, edge_index_g)\n",
    "\n",
    "    # only nodes of this task in the subgraph\n",
    "    else:\n",
    "        # edge index in the original graph\n",
    "        edge_index_g, _ = subgraph(node_ids_g, G.edge_index, None)\n",
    "        # all neighbors are in the subgraph already\n",
    "        node_ids_g_all = node_ids_g\n",
    "        # all nodes are target nodes\n",
    "        target_ids_g = node_ids_g_all\n",
    "        # node ids in the subgraph\n",
    "        target_ids_sub = np.arange(node_ids_g_all.shape[0])\n",
    "        # edge index in the subgraph\n",
    "        edge_index_sub = map_edge_index(node_ids_g_all, edge_index_g)\n",
    "\n",
    "    features = G.x[node_ids_g_all]\n",
    "    labels = G.y[node_ids_g_all]\n",
    "    # map the ids to subgraph\n",
    "    split = map_split(node_ids_g_all, G.splits[key])\n",
    "    # number of nodes in the subgraph\n",
    "    num_nodes = node_ids_g_all.shape[0]\n",
    "\n",
    "    sub_g = Data(x=features,\n",
    "                 edge_index=edge_index_sub,\n",
    "                 y=labels)\n",
    "\n",
    "    # node id in the subgraph\n",
    "    sub_g.n_id_sub = torch.arange(num_nodes)\n",
    "    # node id in the original graph\n",
    "    sub_g.n_id_original = node_ids_g_all\n",
    "    sub_g.split = split\n",
    "    sub_g.target_classes = target_classes\n",
    "    # target ids in the sub graph\n",
    "    sub_g.target_ids_sub = target_ids_sub\n",
    "    # target ids in the original graph\n",
    "    sub_g.taget_ids_g = target_ids_g\n",
    "\n",
    "    return sub_g"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 62, 98, 25, 92]\n",
      "[52, 90, 79, 29, 54]\n"
     ]
    }
   ],
   "source": [
    "sub_g1 = prepare_sub_graph(G, list(G.groups.keys())[0], Cross_Task_Message_Passing=False)\n",
    "sub_g2 = prepare_sub_graph(G, list(G.groups.keys())[1], Cross_Task_Message_Passing=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label for first group\n",
      "tensor([[0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1., 0.]])\n",
      "true label for second group\n",
      "tensor([[1., 0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 1., 1., 0.]])\n",
      "###########################\n",
      "meaning for the shared node, the example node id 372363\n",
      "true label in t0:  tensor([0., 0., 0., 1., 0.])\n",
      "true label in t1:  tensor([0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "target_classes_groups = []\n",
    "target_classes_groups.append(sub_g1.target_classes)\n",
    "target_classes_groups.append(sub_g1.target_classes)\n",
    "\n",
    "sub_g1.y = sub_g1.y[:, target_classes_groups[0]]\n",
    "print(\"true label for first group\")\n",
    "print(sub_g1.y[:3])\n",
    "cls_seen = torch.flatten(torch.tensor(target_classes_groups))\n",
    "sub_g2.y = sub_g2.y[:, cls_seen]\n",
    "print(\"true label for second group\")\n",
    "print(sub_g2.y[:3])\n",
    "print(\"###########################\")\n",
    "print(\"meaning for the shared node, the example node id\", id)\n",
    "# ids of the target nodes in the subgraph1\n",
    "index1 = G.groups[list(G.groups.keys())[0]].index(id)\n",
    "# ids of the target nodes in the subgraph2\n",
    "index2 = G.groups[list(G.groups.keys())[1]].index(id)\n",
    "label1 = sub_g1.y[index1]\n",
    "label2 = sub_g2.y[index2]\n",
    "print(\"true label in t0: \", label1)\n",
    "print(\"true label in t1: \",label2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
